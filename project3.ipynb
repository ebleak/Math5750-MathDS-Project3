{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "SmWUvOCl4d3p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#For this command I asked chatgpt to give me an explination of what each parameter of the function MLPClassifier does to better understand how to modify them\n",
        "\n",
        "#Baseline model with default parameters\n",
        "mlp_baseline = MLPClassifier(hidden_layer_sizes=(128,),\n",
        "                             activation='relu',\n",
        "                             solver='adam',\n",
        "                             learning_rate_init=0.001,\n",
        "                             early_stopping=False,\n",
        "                             alpha=0.0001,\n",
        "                             max_iter=20,\n",
        "                             random_state=42,\n",
        "                             verbose=False)\n",
        "\n",
        "start_time = time.time()\n",
        "mlp_baseline.fit(X_train, y_train)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "y_pred = mlp_baseline.predict(X_test)\n",
        "\n",
        "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(f\"Baseline Training Time: {train_time:.2f} s\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4ec951-8cae-4d40-ae5a-d34404011de6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 0.886\n",
            "Baseline Training Time: 33.52 s\n",
            "[[823   2  22  21   4   2 120   0   6   0]\n",
            " [  2 980   2   9   4   0   2   0   1   0]\n",
            " [ 19   0 847   9  63   1  59   0   2   0]\n",
            " [ 18   8  22 879  48   0  23   0   2   0]\n",
            " [  0   1 119  21 807   0  50   0   2   0]\n",
            " [  0   0   0   1   0 961   0  16   3  19]\n",
            " [102   2 106  20  70   0 691   0   9   0]\n",
            " [  0   0   0   0   0  19   0 954   0  27]\n",
            " [  7   0   7   4   5   6   8   3 959   1]\n",
            " [  1   0   0   0   0   9   1  30   0 959]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcation to iterate over different conditions with the baseline as default\n",
        "def train_mlp(X_train, y_train, X_test, y_test,\n",
        "              layers=(128,),\n",
        "              activation='relu',\n",
        "              solver='adam',\n",
        "              learning=0.001,\n",
        "              estop=False,\n",
        "              alpha=0.0001,\n",
        "              max_iter=20, #Do not change\n",
        "              random_state=42, #Do not change\n",
        "              verbose=False): #Do not change\n",
        "\n",
        "    #Define Model\n",
        "    model = MLPClassifier(hidden_layer_sizes=layers,\n",
        "                          activation=activation,\n",
        "                          solver=solver,\n",
        "                          learning_rate_init=learning,\n",
        "                          early_stopping=estop,\n",
        "                          alpha=alpha,\n",
        "                          max_iter=max_iter,\n",
        "                          random_state=random_state,\n",
        "                          verbose=verbose)\n",
        "\n",
        "    #Train\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    #Evaluation Metrics\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f} | Training Time: {train_time:.2f} s\")\n",
        "    print(conf_mat)\n",
        "\n",
        "    return acc, conf_mat"
      ],
      "metadata": {
        "id": "hSK2aswvzkj1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Different Conditions\n",
        "params = [\n",
        "    ((128,), 'relu', 'adam', 0.001, False), #1 hidden layer neuron count test\n",
        "    ((256,), 'relu', 'adam', 0.001, False), #1 hidden layer neuron count test\n",
        "    ((256,128), 'relu', 'adam', 0.001, False), #2 hidden layers test\n",
        "    ((256,128,64), 'relu', 'adam', 0.001, False), #3 hidden layers test\n",
        "    ((128,), 'tanh', 'adam', 0.001, False), #Activation test\n",
        "    ((128,), 'relu', 'sgd', 0.001, False), #Solver test\n",
        "    ((128,), 'relu', 'adam', 0.01, False), #Large learning rate test\n",
        "    ((128,), 'relu', 'adam', 0.0001, False), #Small learning rate test\n",
        "    ((128,), 'relu', 'adam', 0.001, True) #Early stopping test\n",
        "]\n",
        "\n",
        "#Iterate over parameters\n",
        "results = []\n",
        "for i, (a,b,c,d,e) in enumerate(params, 1):\n",
        "    print(f\"\\n--- Training Model {i} ---\")\n",
        "    acc, conf_mat = train_mlp(X_train, y_train, X_test, y_test, a, b, c, d, e)\n",
        "    results.append((i, acc, conf_mat))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJvbf4UrzyGP",
        "outputId": "97a061c5-09cb-4340-b027-a37489780be1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Model 1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8860 | Training Time: 68.15 s\n",
            "[[823   2  22  21   4   2 120   0   6   0]\n",
            " [  2 980   2   9   4   0   2   0   1   0]\n",
            " [ 19   0 847   9  63   1  59   0   2   0]\n",
            " [ 18   8  22 879  48   0  23   0   2   0]\n",
            " [  0   1 119  21 807   0  50   0   2   0]\n",
            " [  0   0   0   1   0 961   0  16   3  19]\n",
            " [102   2 106  20  70   0 691   0   9   0]\n",
            " [  0   0   0   0   0  19   0 954   0  27]\n",
            " [  7   0   7   4   5   6   8   3 959   1]\n",
            " [  1   0   0   0   0   9   1  30   0 959]]\n",
            "\n",
            "--- Training Model 2 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8898 | Training Time: 101.83 s\n",
            "[[849   3  15  22   6   1  95   0   9   0]\n",
            " [  5 977   2  10   5   0   1   0   0   0]\n",
            " [ 22   1 825   8  87   0  55   0   2   0]\n",
            " [ 18   8  21 871  63   0  14   0   5   0]\n",
            " [  0   1  95  16 844   0  41   0   3   0]\n",
            " [  0   0   0   1   0 960   0  24   1  14]\n",
            " [104   2  91  26  74   0 695   0   8   0]\n",
            " [  0   0   0   0   0   8   0 955   0  37]\n",
            " [ 10   1  10   5   4   6   5   4 955   0]\n",
            " [  1   0   0   1   0   7   1  23   0 967]]\n",
            "\n",
            "--- Training Model 3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8901 | Training Time: 128.93 s\n",
            "[[876   1  15  13   2   1  85   0   7   0]\n",
            " [  6 979   3   6   1   0   4   0   1   0]\n",
            " [ 23   0 846   7  59   0  64   0   1   0]\n",
            " [ 40   9  12 893  21   1  20   0   4   0]\n",
            " [  3   0 104  36 796   0  59   0   2   0]\n",
            " [  1   0   0   0   0 959   0  27   0  13]\n",
            " [157   1  84  25  60   0 667   0   6   0]\n",
            " [  0   0   0   0   0   9   0 977   0  14]\n",
            " [  3   0   6   3   5   3   9   6 965   0]\n",
            " [  0   0   0   0   0  11   1  45   0 943]]\n",
            "\n",
            "--- Training Model 4 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8863 | Training Time: 143.37 s\n",
            "[[824   0  16  22   4   1 127   0   6   0]\n",
            " [  4 979   1  11   3   0   2   0   0   0]\n",
            " [ 19   0 847   7  50   1  72   0   4   0]\n",
            " [ 22   4  17 876  40   2  31   0   8   0]\n",
            " [  0   1 114  24 803   0  54   0   4   0]\n",
            " [  1   0   1   1   0 949   0  23   0  25]\n",
            " [134   0  88  20  54   0 696   0   8   0]\n",
            " [  0   0   0   0   0  12   0 956   1  31]\n",
            " [  4   0   3   4   3   4   9   4 969   0]\n",
            " [  0   0   0   0   0   3   1  32   0 964]]\n",
            "\n",
            "--- Training Model 5 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8837 | Training Time: 74.87 s\n",
            "[[798   3  15  30   7   0 138   0   9   0]\n",
            " [  4 968   0  17   5   0   3   0   3   0]\n",
            " [ 14   1 817  14  85   2  62   1   4   0]\n",
            " [ 14   8  15 893  34   1  31   0   4   0]\n",
            " [  2   1  95  22 833   1  42   0   4   0]\n",
            " [  0   0   0   1   0 951   0  24   4  20]\n",
            " [ 90   2  83  28  76   0 714   0   6   1]\n",
            " [  0   0   0   0   0  23   0 949   0  28]\n",
            " [  4   1   7   8   6   4  13   5 952   0]\n",
            " [  0   0   0   0   0  12   1  25   0 962]]\n",
            "\n",
            "--- Training Model 6 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8646 | Training Time: 51.53 s\n",
            "[[812   1  11  52   2   0 110   0  11   1]\n",
            " [  1 958   4  27   4   0   5   0   1   0]\n",
            " [ 16   1 783  16 105   1  73   0   5   0]\n",
            " [ 21  10  11 886  34   1  32   0   5   0]\n",
            " [  0   1  95  34 797   0  69   0   4   0]\n",
            " [  0   0   0   0   0 928   0  46   2  24]\n",
            " [118   2  95  42  85   1 647   0  10   0]\n",
            " [  0   0   0   0   0  30   0 939   0  31]\n",
            " [  1   1   6  10   4   6  19   4 949   0]\n",
            " [  0   0   0   1   0  15   1  36   0 947]]\n",
            "\n",
            "--- Training Model 7 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8671 | Training Time: 58.92 s\n",
            "[[827   3   9  28   2   0 120   0  11   0]\n",
            " [  5 975   0  11   4   0   4   0   1   0]\n",
            " [ 49   1 776  19  81   1  72   0   1   0]\n",
            " [ 34  14  18 862  35   0  31   0   6   0]\n",
            " [  9   0 108  30 791   1  57   0   4   0]\n",
            " [  0   0   0   1   0 905   0  54  24  16]\n",
            " [121   1  75  33  96   1 661   0  12   0]\n",
            " [  0   0   0   0   0   5   0 962   1  32]\n",
            " [  5   1   0   6   2   2   8   3 973   0]\n",
            " [  0   0   0   0   0  10   1  50   0 939]]\n",
            "\n",
            "--- Training Model 8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8781 | Training Time: 60.04 s\n",
            "[[830   0  11  33   2   0 114   0   9   1]\n",
            " [  2 963   2  23   3   0   5   0   2   0]\n",
            " [ 13   0 795  15 101   1  72   0   3   0]\n",
            " [ 16   6  12 897  33   1  31   0   4   0]\n",
            " [  0   0  89  31 810   0  68   0   2   0]\n",
            " [  0   0   0   1   0 939   0  39   3  18]\n",
            " [114   1  83  34  77   0 681   0  10   0]\n",
            " [  0   0   0   0   0  22   0 955   0  23]\n",
            " [  3   1   3   8   4   5   9   4 962   1]\n",
            " [  0   0   0   1   0   8   1  41   0 949]]\n",
            "\n",
            "--- Training Model 9 ---\n",
            "Accuracy: 0.8860 | Training Time: 55.41 s\n",
            "[[853   2   8  14   4   0 109   0  10   0]\n",
            " [  4 978   2   8   4   0   3   0   1   0]\n",
            " [ 27   1 818  11  67   1  72   1   2   0]\n",
            " [ 29   8   8 875  44   1  31   0   4   0]\n",
            " [  1   1 107  18 803   0  69   0   1   0]\n",
            " [  0   0   0   1   0 954   0  27   2  16]\n",
            " [128   0  74  21  68   2 700   0   7   0]\n",
            " [  0   0   0   0   0  16   0 961   0  23]\n",
            " [  8   0   5   3   3   3   6   5 966   1]\n",
            " [  0   0   0   1   0  11   2  34   0 952]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Attempt to run with optimal conditions\n",
        "params = [\n",
        "    ((256,128), 'relu', 'adam', 0.001, True)\n",
        "]\n",
        "\n",
        "results = []\n",
        "for i, (a,b,c,d,e) in enumerate(params, 1):\n",
        "    print(f\"\\n--- Training Model {i} ---\")\n",
        "    acc, conf_mat = train_mlp(X_train, y_train, X_test, y_test, a, b, c, d, e)\n",
        "    results.append((i, acc, conf_mat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ2s7FqWH5p4",
        "outputId": "33de5e3c-27e9-4ae5-d3cd-e2578db876e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Model 1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8894 | Training Time: 121.08 s\n",
            "[[837   2  19  21   4   0 110   0   6   1]\n",
            " [  3 978   2  13   1   0   2   0   1   0]\n",
            " [ 15   1 837  14  76   1  56   0   0   0]\n",
            " [ 16   6   8 911  29   0  29   0   1   0]\n",
            " [  1   0 101  30 813   0  54   0   1   0]\n",
            " [  0   0   0   0   0 954   0  27   2  17]\n",
            " [125   1  91  28  73   0 676   0   6   0]\n",
            " [  0   0   0   0   0   8   0 958   1  33]\n",
            " [  6   1   6   9   2   6   7   3 960   0]\n",
            " [  0   0   0   0   0   9   1  20   0 970]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6acfae53-b955-4f62-f16c-01cf84334724"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "#Defining the model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_sizes=[256, 128], activation='relu', dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        layers = []\n",
        "        input_size = 28 * 28\n",
        "\n",
        "        for h in hidden_sizes:\n",
        "            layers.append(nn.Linear(input_size, h))\n",
        "            if activation == 'relu':\n",
        "                layers.append(nn.ReLU())\n",
        "            elif activation == 'tanh':\n",
        "                layers.append(nn.Tanh())\n",
        "            elif activation == 'sigmoid':\n",
        "                layers.append(nn.Sigmoid())\n",
        "            if dropout > 0:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            input_size = h\n",
        "\n",
        "        layers.append(nn.Linear(input_size, 10))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.net(x)\n",
        "\n",
        "#Function for Training\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=5, device='cuda'):\n",
        "    model.to(device)\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                preds = model(images).argmax(dim=1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "        val_acc = val_correct / val_total\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {running_loss/len(train_loader):.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    return total_time\n",
        "\n",
        "#Defining the test run\n",
        "def evaluate_model(model, test_loader, device='cuda'):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images).argmax(dim=1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "    return np.array(y_true), np.array(y_pred)"
      ],
      "metadata": {
        "id": "0REsDBunNmEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30871004-23bb-4cec-80b0-bd5a4e400c51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variations\n",
        "param_sets = [\n",
        "    {\"hidden_sizes\": [128], \"activation\": \"relu\", \"optimizer\": \"adam\", \"lr\": 0.001, \"dropout\": 0.0},\n",
        "    {\"hidden_sizes\": [256, 128], \"activation\": \"relu\", \"optimizer\": \"adam\", \"lr\": 0.001, \"dropout\": 0.0},\n",
        "    {\"hidden_sizes\": [256, 128, 64], \"activation\": \"tanh\", \"optimizer\": \"adam\", \"lr\": 0.001, \"dropout\": 0.2},\n",
        "    {\"hidden_sizes\": [128], \"activation\": \"relu\", \"optimizer\": \"sgd\", \"lr\": 0.01, \"dropout\": 0.0},\n",
        "    {\"hidden_sizes\": [128], \"activation\": \"relu\", \"optimizer\": \"adam\", \"lr\": 0.001, \"dropout\": 0.3},\n",
        "]\n",
        "\n",
        "#Iterate through variations\n",
        "results = []\n",
        "for i, params in enumerate(param_sets, 1):\n",
        "    print(f\"\\n--- Training Model {i}: {params} ---\")\n",
        "    model = MLP(hidden_sizes=params[\"hidden_sizes\"],\n",
        "                activation=params[\"activation\"],\n",
        "                dropout=params[\"dropout\"]).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if params[\"optimizer\"] == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
        "    elif params[\"optimizer\"] == \"sgd\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=params[\"lr\"])\n",
        "\n",
        "    #Training and evalution\n",
        "    train_time = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=5, device=device)\n",
        "    y_true, y_pred = evaluate_model(model, test_loader, device)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f} | Training Time: {train_time:.2f} s\")\n",
        "    print(cm)"
      ],
      "metadata": {
        "id": "ALugEHFrHdQX",
        "outputId": "f9338869-eabc-44a5-a3ef-7bf8a0e34def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Model 1: {'hidden_sizes': [128], 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.001, 'dropout': 0.0} ---\n",
            "Epoch [1/5] - Loss: 0.6261, Val Acc: 0.8338\n",
            "Epoch [2/5] - Loss: 0.4373, Val Acc: 0.8538\n",
            "Epoch [3/5] - Loss: 0.3950, Val Acc: 0.8619\n",
            "Epoch [4/5] - Loss: 0.3700, Val Acc: 0.8655\n",
            "Epoch [5/5] - Loss: 0.3486, Val Acc: 0.8590\n",
            "Accuracy: 0.8552 | Training Time: 4.97 s\n",
            "[[643   2  16  62   5   3 259   0  10   0]\n",
            " [  2 956   1  31   6   0   2   0   2   0]\n",
            " [  5   1 831  17  64   1  77   0   4   0]\n",
            " [  6   8   8 914  22   0  36   0   6   0]\n",
            " [  0   0 157  55 690   4  90   0   4   0]\n",
            " [  0   0   0   1   0 958   0  26   2  13]\n",
            " [ 53   1 110  53  50   1 718   0  14   0]\n",
            " [  0   0   0   0   0  39   0 923   0  38]\n",
            " [  1   1   2   6   3   3  14   5 965   0]\n",
            " [  0   0   0   0   0  14   1  31   0 954]]\n",
            "\n",
            "--- Training Model 2: {'hidden_sizes': [256, 128], 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.001, 'dropout': 0.0} ---\n",
            "Epoch [1/5] - Loss: 0.5939, Val Acc: 0.8362\n",
            "Epoch [2/5] - Loss: 0.4016, Val Acc: 0.8548\n",
            "Epoch [3/5] - Loss: 0.3559, Val Acc: 0.8699\n",
            "Epoch [4/5] - Loss: 0.3285, Val Acc: 0.8768\n",
            "Epoch [5/5] - Loss: 0.3089, Val Acc: 0.8686\n",
            "Accuracy: 0.8618 | Training Time: 5.91 s\n",
            "[[705   2  19  21   5   2 238   0   8   0]\n",
            " [  2 974   0  17   4   0   1   0   2   0]\n",
            " [  6   1 637  11 248   0  94   0   3   0]\n",
            " [ 18  16  10 857  49   0  46   0   4   0]\n",
            " [  0   0  37  22 898   0  42   0   1   0]\n",
            " [  0   0   0   0   0 956   0  28   1  15]\n",
            " [ 67   2  52  27 126   0 712   0  14   0]\n",
            " [  0   0   0   0   0  24   0 951   1  24]\n",
            " [  2   1   4   4   6   3   6   2 972   0]\n",
            " [  0   0   0   0   0   8   1  35   0 956]]\n",
            "\n",
            "--- Training Model 3: {'hidden_sizes': [256, 128, 64], 'activation': 'tanh', 'optimizer': 'adam', 'lr': 0.001, 'dropout': 0.2} ---\n",
            "Epoch [1/5] - Loss: 0.6514, Val Acc: 0.8362\n",
            "Epoch [2/5] - Loss: 0.4455, Val Acc: 0.8313\n",
            "Epoch [3/5] - Loss: 0.4091, Val Acc: 0.8616\n",
            "Epoch [4/5] - Loss: 0.3892, Val Acc: 0.8638\n",
            "Epoch [5/5] - Loss: 0.3709, Val Acc: 0.8632\n",
            "Accuracy: 0.8619 | Training Time: 6.00 s\n",
            "[[818   2   4  30   1   0 131   0  13   1]\n",
            " [  3 961   0  29   2   0   4   0   1   0]\n",
            " [ 10   2 847  11  43   1  84   0   2   0]\n",
            " [ 24   6   4 890  30   1  40   0   5   0]\n",
            " [  0   1 232  38 617   0 105   0   7   0]\n",
            " [  0   0   0   1   0 937   0  45   3  14]\n",
            " [125   1 106  29  47   0 679   0  13   0]\n",
            " [  0   0   0   0   0  22   0 950   0  28]\n",
            " [  1   1   2   2   2   3  14   5 970   0]\n",
            " [  0   0   0   0   0   8   0  41   1 950]]\n",
            "\n",
            "--- Training Model 4: {'hidden_sizes': [128], 'activation': 'relu', 'optimizer': 'sgd', 'lr': 0.01, 'dropout': 0.0} ---\n",
            "Epoch [1/5] - Loss: 1.5618, Val Acc: 0.6710\n",
            "Epoch [2/5] - Loss: 0.8981, Val Acc: 0.7279\n",
            "Epoch [3/5] - Loss: 0.7458, Val Acc: 0.7637\n",
            "Epoch [4/5] - Loss: 0.6702, Val Acc: 0.7763\n",
            "Epoch [5/5] - Loss: 0.6203, Val Acc: 0.7909\n",
            "Accuracy: 0.7819 | Training Time: 5.01 s\n",
            "[[795  10  11  79  11   1  69   0  24   0]\n",
            " [  5 929  14  40  10   0   0   0   2   0]\n",
            " [ 19   2 602   9 266   2  83   0  17   0]\n",
            " [ 40  15   4 825  53   1  57   0   5   0]\n",
            " [  0   3  65  34 846   0  45   0   7   0]\n",
            " [  1   0   0   1   0 780   0 128   7  83]\n",
            " [213   4 123  48 273   2 296   0  41   0]\n",
            " [  0   0   0   0   0  33   0 871   0  96]\n",
            " [  1   2  11  11   4   4  21   9 935   2]\n",
            " [  0   0   0   2   0   8   0  49   1 940]]\n",
            "\n",
            "--- Training Model 5: {'hidden_sizes': [128], 'activation': 'relu', 'optimizer': 'adam', 'lr': 0.001, 'dropout': 0.3} ---\n",
            "Epoch [1/5] - Loss: 0.6850, Val Acc: 0.8293\n",
            "Epoch [2/5] - Loss: 0.4622, Val Acc: 0.8482\n",
            "Epoch [3/5] - Loss: 0.4130, Val Acc: 0.8623\n",
            "Epoch [4/5] - Loss: 0.3881, Val Acc: 0.8685\n",
            "Epoch [5/5] - Loss: 0.3715, Val Acc: 0.8689\n",
            "Accuracy: 0.8612 | Training Time: 5.16 s\n",
            "[[827   1  16  48   5   0  92   0  10   1]\n",
            " [  3 960   4  24   5   0   2   0   2   0]\n",
            " [ 17   2 769   9 144   1  55   0   3   0]\n",
            " [ 29   8   9 877  43   0  30   0   4   0]\n",
            " [  0   0 101  25 810   0  62   0   2   0]\n",
            " [  0   0   0   1   0 949   0  28   2  20]\n",
            " [139   1 115  41  91   0 599   0  14   0]\n",
            " [  0   0   0   0   0  33   0 877   0  90]\n",
            " [  2   1   3   6   6   2  11   5 964   0]\n",
            " [  0   0   0   0   0   3   1  16   0 980]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define CNN Model with MaxPool2d layers\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, conv_channels=[32, 64, 128], fc_size=128, activation='relu', dropout=0.25):\n",
        "        super().__init__()\n",
        "\n",
        "        self.act = nn.ReLU() if activation == 'relu' else nn.Tanh()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, conv_channels[0], kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(conv_channels[0], conv_channels[1], kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(conv_channels[1], conv_channels[2], kernel_size=3, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(conv_channels[2] * 3 * 3, fc_size)\n",
        "        self.fc2 = nn.Linear(fc_size, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.act(self.conv1(x)))\n",
        "        x = self.pool(self.act(self.conv2(x)))\n",
        "        x = self.pool(self.act(self.conv3(x)))\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(self.act(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lym0JnT9HlaN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run CNN Model\n",
        "cnn_params = {\n",
        "    \"conv_channels\": [32, 64, 128],\n",
        "    \"fc_size\": 128,\n",
        "    \"activation\": \"relu\",\n",
        "    \"dropout\": 0.25,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 5\n",
        "}\n",
        "\n",
        "print(f\"\\n--- Training Improved CNN with parameters: {cnn_params} ---\")\n",
        "\n",
        "cnn_model = CNN(conv_channels=cnn_params[\"conv_channels\"],\n",
        "                fc_size=cnn_params[\"fc_size\"],\n",
        "                activation=cnn_params[\"activation\"],\n",
        "                dropout=cnn_params[\"dropout\"]).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=cnn_params[\"learning_rate\"])\n",
        "\n",
        "#Training and Evulation\n",
        "train_time = train_model(cnn_model, train_loader, val_loader, optimizer, criterion,\n",
        "                         epochs=cnn_params[\"epochs\"], device=device)\n",
        "\n",
        "y_true, y_pred = evaluate_model(cnn_model, test_loader, device)\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f} | Training Time: {train_time:.2f} s\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "Lo-h9Mk2NoDW",
        "outputId": "717acfc4-bea9-45fa-cbef-098f60db4959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Improved CNN with parameters: {'conv_channels': [32, 64, 128], 'fc_size': 128, 'activation': 'relu', 'dropout': 0.25, 'optimizer': 'adam', 'learning_rate': 0.001, 'epochs': 5} ---\n",
            "Epoch [1/5] - Loss: 0.6652, Val Acc: 0.8486\n",
            "Epoch [2/5] - Loss: 0.3858, Val Acc: 0.8774\n",
            "Epoch [3/5] - Loss: 0.3205, Val Acc: 0.8843\n",
            "Epoch [4/5] - Loss: 0.2859, Val Acc: 0.9023\n",
            "Epoch [5/5] - Loss: 0.2606, Val Acc: 0.9111\n",
            "Accuracy: 0.9035 | Training Time: 11.82 s\n",
            "[[821   0  13  17   4   1 139   0   5   0]\n",
            " [  2 974   0  15   3   0   4   0   2   0]\n",
            " [ 12   1 859   9  59   0  59   0   1   0]\n",
            " [ 18   3   8 910  29   0  31   0   1   0]\n",
            " [  1   1  64  30 845   0  58   0   1   0]\n",
            " [  0   0   0   1   0 976   0  14   0   9]\n",
            " [ 87   1  58  27  73   0 749   0   5   0]\n",
            " [  0   0   0   0   0   5   0 984   0  11]\n",
            " [  5   1   4   1   5   1   3   5 975   0]\n",
            " [  1   0   0   0   0   4   0  53   0 942]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "#Transfer Learning\n",
        "transfer_params = {\n",
        "    \"base_model\": \"ResNet18\",\n",
        "    \"weights\": \"IMAGENET1K_V1\",\n",
        "    \"frozen_layers\": True,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"epochs\": 3\n",
        "}\n",
        "\n",
        "print(f\"\\n--- Training Transfer Learning Model ({transfer_params['base_model']}) ---\")\n",
        "\n",
        "resnet = models.resnet18(weights=transfer_params[\"weights\"])\n",
        "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
        "if transfer_params[\"frozen_layers\"]:\n",
        "    for param in list(resnet.parameters())[:-2]:\n",
        "        param.requires_grad = False\n",
        "\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=transfer_params[\"learning_rate\"])\n",
        "\n",
        "#Training and Evaluation\n",
        "train_time = train_model(resnet, train_loader, val_loader, optimizer, criterion,\n",
        "                         epochs=transfer_params[\"epochs\"], device=device)\n",
        "\n",
        "y_true, y_pred = evaluate_model(resnet, test_loader, device)\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f} | Training Time: {train_time:.2f} s\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "fz1MdumIHqje",
        "outputId": "6b75dabf-9960-488b-dc86-324640417f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Transfer Learning Model (ResNet18) ---\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 75.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3] - Loss: 1.8653, Val Acc: 0.5202\n",
            "Epoch [2/3] - Loss: 1.3700, Val Acc: 0.5834\n",
            "Epoch [3/3] - Loss: 1.2193, Val Acc: 0.6107\n",
            "Accuracy: 0.5999 | Training Time: 12.92 s\n",
            "[[585  24  92 103  21  11 106   5  45   8]\n",
            " [ 26 843  15  75  11   2  16   1   7   4]\n",
            " [ 81  19 483  16 128   8 211   2  49   3]\n",
            " [122 125  42 569  37  14  65   6  16   4]\n",
            " [ 51  13 226  50 435   8 151   1  55  10]\n",
            " [ 11   4   9   2   4 647  18 226  32  47]\n",
            " [202  20 211  59 108   8 326   5  51  10]\n",
            " [  3   5   1   3   0 139   3 735   7 104]\n",
            " [ 57   8  56  30  27  56  39  45 631  51]\n",
            " [  6  10  11   8  19  56   8  92  45 745]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5_d7xHUOH3Yc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}