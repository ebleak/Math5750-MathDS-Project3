{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76cae6c-4959-4fbd-83e3-895e31069b02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "#For this command I asked chatgpt to give me an explination of what each parameter of the function MLPClassifier does to better understand how to modify them\n",
        "\n",
        "#Inital model with default parameters\n",
        "mlp_baseline = MLPClassifier(hidden_layer_sizes=(128,),\n",
        "                             activation='relu',\n",
        "                             solver='adam',\n",
        "                             learning_rate_init=0.001,\n",
        "                             early_stopping=False,\n",
        "                             alpha=0.0001,\n",
        "                             max_iter=20,\n",
        "                             random_state=42,\n",
        "                             verbose=False)\n",
        "\n",
        "start_time = time.time()\n",
        "mlp_baseline.fit(X_train, y_train)\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "y_pred = mlp_baseline.predict(X_test)\n",
        "\n",
        "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(f\"Baseline Training Time: {train_time:.2f} s\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8625e6-c634-402a-d86a-e1f55f6aedd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 0.886\n",
            "Baseline Training Time: 66.09 s\n",
            "[[823   2  22  21   4   2 120   0   6   0]\n",
            " [  2 980   2   9   4   0   2   0   1   0]\n",
            " [ 19   0 847   9  63   1  59   0   2   0]\n",
            " [ 18   8  22 879  48   0  23   0   2   0]\n",
            " [  0   1 119  21 807   0  50   0   2   0]\n",
            " [  0   0   0   1   0 961   0  16   3  19]\n",
            " [102   2 106  20  70   0 691   0   9   0]\n",
            " [  0   0   0   0   0  19   0 954   0  27]\n",
            " [  7   0   7   4   5   6   8   3 959   1]\n",
            " [  1   0   0   0   0   9   1  30   0 959]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcation to iterate over different conditions with the baseline as default\n",
        "def train_mlp(X_train, y_train, X_test, y_test,\n",
        "              layers=(128,),           # hidden_layer_sizes\n",
        "              activation='relu',           # activation\n",
        "              solver='adam',           # solver\n",
        "              learning=0.001,            # learning_rate_init\n",
        "              estop=False,            # early_stopping\n",
        "              alpha=0.0001,       # regularization strength\n",
        "              max_iter=20,        # max iterations\n",
        "              random_state=42,    # random seed\n",
        "              verbose=False):     # training verbosity\n",
        "\n",
        "    #Define Model\n",
        "    model = MLPClassifier(hidden_layer_sizes=layers,\n",
        "                          activation=activation,\n",
        "                          solver=solver,\n",
        "                          learning_rate_init=learning,\n",
        "                          early_stopping=estop,\n",
        "                          alpha=alpha,\n",
        "                          max_iter=max_iter,\n",
        "                          random_state=random_state,\n",
        "                          verbose=verbose)\n",
        "\n",
        "    #Train\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    #Evaluation Metrics\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f} | Training Time: {train_time:.2f} s\")\n",
        "\n",
        "    return model, acc, conf_mat"
      ],
      "metadata": {
        "id": "hSK2aswvzkj1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterate over different conditions\n",
        "params = [\n",
        "    ((128,), 'relu', 'adam', 0.001, False),\n",
        "    ((256,128), 'relu', 'adam', 0.001, False),\n",
        "    ((256,128,64), 'tanh', 'adam', 0.001, False),\n",
        "    ((128,), 'relu', 'sgd', 0.01, False),\n",
        "    ((128,), 'relu', 'adam', 0.001, True),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for i, (a,b,c,d,e) in enumerate(params, 1):\n",
        "    print(f\"\\n--- Training Model {i} ---\")\n",
        "    _, acc, _ = train_mlp(X_train, y_train, X_test, y_test, a, b, c, d, e)\n",
        "    results.append((i, acc))"
      ],
      "metadata": {
        "id": "qJvbf4UrzyGP",
        "outputId": "12093620-05ca-447c-a393-fd882bd4a900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Model 1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8860 | Training Time: 61.59 s\n",
            "\n",
            "--- Training Model 2 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8901 | Training Time: 142.37 s\n",
            "\n",
            "--- Training Model 3 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8812 | Training Time: 186.63 s\n",
            "\n",
            "--- Training Model 4 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8850 | Training Time: 53.54 s\n",
            "\n",
            "--- Training Model 5 ---\n",
            "Accuracy: 0.8860 | Training Time: 54.34 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# your code here"
      ],
      "metadata": {
        "id": "0REsDBunNmEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}